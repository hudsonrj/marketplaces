# üõí Sistema de Monitoramento de Marketplaces com Agentes IA

Este √© um sistema avan√ßado de **Intelig√™ncia de Pre√ßos e Monitoramento de Marketplaces** desenvolvido com **Next.js 16**, **Playwright** e **Intelig√™ncia Artificial**. A aplica√ß√£o permite cadastrar produtos e utilizar agentes aut√¥nomos para varrer grandes e-commerces (Mercado Livre, Amazon, Shopee), coletar dados de pre√ßos em tempo real e analisar as ofertas utilizando LLMs (Large Language Models) para garantir a correspond√™ncia exata dos produtos.

## üöÄ Funcionalidades Principais

### 1. Gest√£o de Produtos
*   **CRUD Completo**: Cadastro, edi√ß√£o e remo√ß√£o de produtos para monitoramento.
*   **Status Ativo/Inativo**: Controle quais produtos devem ser monitorados pelos agentes.
*   **Vis√£o Geral**: Tabela com indicadores r√°pidos como "Melhor Pre√ßo Recente" e contagem de buscas realizadas.

### 2. Marketplaces Suportados
O sistema suporta nativamente os maiores e-commerces do Brasil:
*   üü° **Mercado Livre**: Busca inteligente com ordena√ß√£o por menor pre√ßo, extra√ß√£o de frete, vendedor e localiza√ß√£o.
*   ‚ö´ **Amazon**: Coleta robusta com detec√ß√£o de CAPTCHA e extra√ß√£o de detalhes de entrega e parcelamento.
*   üü† **Shopee**: Navega√ß√£o capaz de lidar com popups e carregamento din√¢mico de produtos.

### 3. Intelig√™ncia Artificial (AI Core) & Enriquecimento de Dados
A "c√©rebro" da aplica√ß√£o utiliza modelos de linguagem (LLMs) para transformar dados brutos e n√£o estruturados da web em informa√ß√µes precisas e acion√°veis.

#### üß† Como a IA Refina os Dados
O processo de enriquecimento ocorre em etapas para cada oferta encontrada:

1.  **An√°lise Sem√¢ntica (Match Analysis)**:
    *   O scraper envia o t√≠tulo bruto (ex: "Iphone 13 128gb vitrine") e o pre√ßo.
    *   A IA compara com o produto alvo (ex: "iPhone 13 128GB Novo") e gera um **Match Score (0-100)**.
    *   **Racioc√≠nio**: A IA fornece uma explica√ß√£o textual do porqu√™ aquele produto √© ou n√£o uma correspond√™ncia (ex: "Score 20: O produto encontrado √© usado/vitrine, enquanto o alvo √© novo").

2.  **Normaliza√ß√£o e Extra√ß√£o**:
    *   **Nomes**: Transforma t√≠tulos longos de SEO (ex: "Smartphone Apple iPhone 13 128gb Tela 6.1 C√¢mera Dupla...") em nomes can√¥nicos limpos (ex: "iPhone 13 128GB").
    *   **Geolocaliza√ß√£o**: Extrai Cidade e Estado de strings de localiza√ß√£o sujas (ex: "Enviado de Vila Mariana, SP" -> City: "S√£o Paulo", State: "SP").

3.  **Descoberta de Novos Produtos**:
    *   Se o agente encontra um produto que √© v√°lido mas diferente do alvo (ex: um "iPhone 14" enquanto buscava o "13"), a IA o identifica como um **Candidato a Novo Produto**.
    *   **Verifica√ß√£o de Duplicidade**: Antes de cadastrar, uma segunda camada de IA compara semanticamente este candidato com *todos* os produtos j√° existentes no banco, evitando duplicatas (ex: reconhece que "Galaxy S23" √© o mesmo que "Samsung S23 5G").

### 4. Agentes Aut√¥nomos (Scrapers)
Os agentes n√£o s√£o simples scripts de requisi√ß√£o HTTP; s√£o navegadores completos controlados via c√≥digo.

*   **Navega√ß√£o Humanizada**: Simulam comportamento humano com rolagens de p√°gina (scroll), movimentos de mouse e tempos de espera aleat√≥rios para evitar detec√ß√£o por sistemas anti-bot.
*   **Resili√™ncia**:
    *   **Shopee**: Lida com popups de marketing e carregamento infinito (infinite scroll).
    *   **Amazon**: Detecta CAPTCHAs e tenta contornar ou alertar.
    *   **Mercado Livre**: Navega por filtros de "Menor Pre√ßo" e ignora an√∫ncios patrocinados irrelevantes.
*   **Isolamento**: Cada Job roda em um contexto de navegador isolado (incognito), garantindo que cookies ou sess√µes anteriores n√£o interfiram nos pre√ßos exibidos.

### 5. Analytics e Dados
*   **Dashboard de Evolu√ß√£o**: Gr√°ficos interativos (Recharts) mostrando o hist√≥rico de pre√ßos (M√≠nimo e M√©dio) ao longo do tempo.
*   **DuckDB Integration**: Utiliza DuckDB para processamento anal√≠tico de alta performance dos dados hist√≥ricos.
*   **Hist√≥rico de Jobs**: Registro completo de todas as buscas realizadas, com status e resultados detalhados.

## üõ†Ô∏è Stack Tecnol√≥gica

*   **Frontend**: Next.js 16 (App Router), React 19, Lucide Icons.
*   **Backend**: Server Actions, Prisma ORM.
*   **Banco de Dados**: SQLite (Dados operacionais) + DuckDB (Analytics).
*   **Automa√ß√£o**: Playwright (Chromium Headless/Headful).
*   **AI/LLM**: OpenAI SDK (Integrado com m√∫ltiplos providers).
*   **Estiliza√ß√£o**: CSS Moderno com design Glassmorphism.

## üì¶ Instala√ß√£o e Configura√ß√£o

### Pr√©-requisitos
*   Node.js 18+
*   NPM ou Yarn

### Passo a Passo

1.  **Clone o reposit√≥rio e instale as depend√™ncias**:
    ```bash
    npm install
    ```

2.  **Instale os navegadores do Playwright**:
    ```bash
    npx playwright install chromium
    ```

3.  **Configure o Banco de Dados**:
    ```bash
    npx prisma migrate dev --name init
    ```

4.  **Vari√°veis de Ambiente**:
    Crie um arquivo `.env` na raiz (opcional se for configurar a IA pela interface, mas recomendado para chaves padr√£o):
    ```env
    DATABASE_URL="file:./dev.db"
    OPENAI_API_KEY="sua-chave-aqui"
    ```

5.  **Inicie o Servidor de Desenvolvimento**:
    ```bash
    npm run dev
    ```
    Acesse `http://localhost:3000` no seu navegador.

## üñ•Ô∏è Estrutura do Projeto

*   `src/app`: Rotas e p√°ginas da aplica√ß√£o (Next.js App Router).
    *   `/products`: Listagem e gest√£o de produtos.
    *   `/products/[id]/analytics`: Dashboard de an√°lise de pre√ßos.
    *   `/settings`: Configura√ß√£o de provedores de IA.
*   `src/lib`: N√∫cleo da l√≥gica de neg√≥cios.
    *   `scraper.ts`: L√≥gica dos agentes de coleta (Playwright).
    *   `ai.ts`: Integra√ß√£o com LLMs para an√°lise de dados.
    *   `duckdb.ts`: Consultas anal√≠ticas otimizadas.
*   `prisma`: Schema do banco de dados e migra√ß√µes.

## üìù Notas de Uso

*   **Execu√ß√£o dos Agentes**: Ao iniciar uma busca ("Job"), o sistema pode abrir uma janela do navegador (se configurado como `headless: false` para debug) ou rodar em segundo plano.
*   **Custos de IA**: O sistema consome tokens da API configurada (OpenAI/Groq) para cada produto analisado. Recomenda-se o uso de modelos eficientes como `gpt-4o-mini` ou `llama-3-70b` via Groq para menor custo e alta velocidade.
